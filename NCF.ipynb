{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import load_rating_data as ld\n",
    "import time\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "from timeit import default_timer as timer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMF(nn.Module):\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        super(GMF, self).__init__() # run nn.Module.__init__()\n",
    "        self.args = args\n",
    "        self.n_users = args.n_users\n",
    "        self.n_items = args.n_items\n",
    "        self.latent_dim = args.latent_dim\n",
    "        \n",
    "        # Embedding Layer\n",
    "        self.embedding_user = nn.Embedding(num_embeddings = self.n_users, embedding_dim = self.latent_dim)\n",
    "        self.embedding_item = nn.Embedding(num_embeddings = self.n_items, embedding_dim = self.latent_dim)\n",
    "        \n",
    "        # One layer\n",
    "        self.affine_output = nn.Linear(in_features = self.latent_dim, out_features = 1)\n",
    "        self.logistic = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, u, i):\n",
    "        \n",
    "        user_embedding = self.embedding_user(u)\n",
    "        item_embedding = self.embedding_item(i)\n",
    "        product = torch.mul(user_embedding, item_embedding) # element-wise product\n",
    "        logits = self.affine_output(product)\n",
    "        rating = self.logistic(logits)\n",
    "        \n",
    "        return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        super(MLP, self).__init__()\n",
    "        self.args = args\n",
    "        self.n_users = args.n_users\n",
    "        self.n_items = args.n_items\n",
    "        self.latent_dim = args.latent_dim\n",
    "        \n",
    "        # Build Layers\n",
    "        # Embedding Layer\n",
    "        self.embedding_user = nn.Embedding(num_embeddings = self.n_users, embedding_dim = self.latent_dim)\n",
    "        self.embedding_item = nn.Embedding(num_embeddings = self.n_items, embedding_dim = self.latent_dim)\n",
    "        \n",
    "        ## Fully Connected Layer\n",
    "        self.fc_layers = nn.ModuleList() # holds submodules in a list\n",
    "        for idx, (in_size, out_size) in enumerate(zip(args.layers[:-1], args.layers[1:])):\n",
    "            self.fc_layers.append(nn.Linear(in_size, out_size))\n",
    "        \n",
    "        ## Final Layer\n",
    "        self.affine_output = nn.Linear(in_features = args.layers[-1], out_features = 1)\n",
    "        self.logistic = nn.Sigmoid()\n",
    "        \n",
    "    \n",
    "    def forward(self, u, i):\n",
    "        \n",
    "        user_embedding = self.embedding_user(u)\n",
    "        item_embedding = self.embedding_item(i)\n",
    "        vector = torch.cat([user_embedding, item_embedding], dim=-1) # concatenate user, item\n",
    "        for idx, _ in enumerate(range(len(self.fc_layers))):\n",
    "            vector = self.fc_layers[idx](vector)\n",
    "            vector = nn.ReLU()(vector)\n",
    "        logits = self.affine_output(vector)\n",
    "        rating = self.logistic(logits)\n",
    "        \n",
    "        return rating\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuMF(nn.Module):\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        super(NeuMF, self).__init__()\n",
    "        self.args = args\n",
    "        self.n_users = args.n_users\n",
    "        self.n_items = args.n_items\n",
    "        self.latent_GMF = args.latent_GMF\n",
    "        self.latent_MLP = args.latent_MLP\n",
    "        \n",
    "        self.embedding_user_MF = nn.Embedding(num_embeddings = self.n_users, embedding_dim = self.latent_GMF)\n",
    "        self.embedding_item_MF = nn.Embedding(num_embeddings = self.n_items, embedding_dim = self.latent_GMF)\n",
    "        self.embedding_user_MLP = nn.Embedding(num_embeddings = self.n_users, embedding_dim = self.latent_MLP)\n",
    "        self.embedding_item_MLP = nn.Embedding(num_embeddings = self.n_items, embedding_dim = self.latent_MLP)\n",
    "        \n",
    "        ## Fully Connected Layer\n",
    "        self.fc_layers = nn.ModuleList() # holds submodules in a list\n",
    "        for idx, (in_size, out_size) in enumerate(zip(args.layers[:-1], args.layers[1:])):\n",
    "            self.fc_layers.append(nn.Linear(in_size, out_size))\n",
    "                        \n",
    "        self.affine_output = nn.Linear(in_features = args.layers[-1] + self.latent_GMF, out_features=1)\n",
    "        self.logistic = nn.Sigmoid()\n",
    "        \n",
    "    \n",
    "    def forward(self, u, i):\n",
    "        user_embedding_MF = self.embedding_user_MF(u)\n",
    "        item_embedding_MF = self.embedding_item_MF(i)\n",
    "        user_embedding_MLP = self.embedding_user_MLP(u)\n",
    "        item_embedding_MLP = self.embedding_item_MLP(i)\n",
    "        \n",
    "        # Multi-Layer Perceptron part\n",
    "        MLP_vector = torch.cat([user_embedding_MLP, item_embedding_MLP], dim=-1)\n",
    "        for idx, _ in enumerate(range(len(self.fc_layers))):\n",
    "            MLP_vector = self.fc_layers[idx](MLP_vector)\n",
    "            MLP_vector = nn.ReLU()(MLP_vector)\n",
    "        \n",
    "        # Martrix Factorization part\n",
    "        MF_vector = torch.mul(user_embedding_MF, item_embedding_MF)\n",
    "        \n",
    "        vector = torch.cat([MLP_vector, MF_vector], dim=-1)\n",
    "        logits = self.affine_output(vector)\n",
    "        rating = self.logistic(logits)\n",
    "        \n",
    "        return rating\n",
    "    \n",
    "    def load_pretrain_weights(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        load pretrained weights from GMF and MLP\n",
    "        \"\"\"\n",
    "        \n",
    "        mlp_model = MLP(self.args)\n",
    "        state_dict = torch.load('./checkpoints/MLP_Epoch10_HR0.1758_NDCG0.1736.model')\n",
    "        mlp_model.load_state_dict(state_dict)\n",
    "        self.embedding_user_MLP.weight.data = mlp_model.embedding_user.weight.data\n",
    "        self.embedding_item_MLP.weight.data = mlp_model.embedding_item.weight.data\n",
    "        for idx in range(len(self.fc_layers)):\n",
    "            self.fc_layers[idx].weight.data = mlp_model.fc_layers[idx].weight.data\n",
    "        \n",
    "        gmf_model = GMF(args)\n",
    "        gmf_model\n",
    "        state_dict = torch.load('./checkpoints/GMF_Epoch10_HR0.1479_NDCG0.1472.model')\n",
    "        gmf_model.load_state_dict(state_dict)\n",
    "        self.embedding_user_MF.weight.data = gmf_model.embedding_user.weight.data\n",
    "        self.embedding_item_MF.weight.data = gmf_model.embedding_item.weight.data\n",
    "        \n",
    "        \n",
    "        self.affine_output.weight.data = 0.5 * torch.cat([mlp_model.affine_output.weight.data, gmf_model.affine_output.weight.data], dim=-1)\n",
    "        self.affine_output.bias.data = 0.5 * (mlp_model.affine_output.bias.data + gmf_model.affine_output.bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict as edict\n",
    "\n",
    "args = edict()\n",
    "\n",
    "# training options\n",
    "args.df = ld.load_rating_1m()\n",
    "args.latent_dim = 32\n",
    "args.epoch = 10                      # training epoch.\n",
    "args.train_n_neg = 3     #memory issue\n",
    "args.test_n_neg = 100     #memory issue\n",
    "args.batch_size = 256\n",
    "args.layers = [64,32,16]\n",
    "args.latent_GMF = 16\n",
    "args.latent_MLP = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "info = ld.information(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GMF(args)\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Evluating Epoch 1] total_loss = 1884.3949, HR = 0.0899, NDCG = 0.0736 time = 159.3931sec\n",
      "[Evluating Epoch 2] total_loss = 0.4397, HR = 0.1287, NDCG = 0.1271 time = 156.5461sec\n",
      "[Evluating Epoch 3] total_loss = 0.0001, HR = 0.1427, NDCG = 0.1419 time = 217.7750sec\n",
      "[Evluating Epoch 4] total_loss = 0.0000, HR = 0.1452, NDCG = 0.1444 time = 210.7375sec\n",
      "[Evluating Epoch 5] total_loss = 0.0000, HR = 0.1458, NDCG = 0.1450 time = 228.6337sec\n",
      "[Evluating Epoch 6] total_loss = 0.0000, HR = 0.1457, NDCG = 0.1450 time = 214.5030sec\n",
      "[Evluating Epoch 7] total_loss = 0.0000, HR = 0.1459, NDCG = 0.1452 time = 238.8860sec\n",
      "[Evluating Epoch 8] total_loss = 0.0000, HR = 0.1469, NDCG = 0.1462 time = 225.0136sec\n",
      "[Evluating Epoch 9] total_loss = 0.0000, HR = 0.1479, NDCG = 0.1472 time = 219.4985sec\n",
      "[Evluating Epoch 10] total_loss = 0.0000, HR = 0.1479, NDCG = 0.1472 time = 159.1954sec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# epoch\n",
    "for epoch_id in range(1, args.epoch + 1):\n",
    "    train_loader = info.train_dataloader\n",
    "    start_epoch = timer()\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        user, item, rating = batch[0], batch[1], batch[2]\n",
    "        # mini-batch update\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(user, item)\n",
    "        loss = loss_function(prediction.view(-1), rating)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    hit = 0\n",
    "    ndcg = 0\n",
    "    test_loader = info.test_dataloader\n",
    "    for batch_idx, batch in enumerate(test_loader):\n",
    "        user, item, neg_items = batch[0], batch[1], batch[2]\n",
    "        # mini-batch update\n",
    "        test_pred = model(user, item)\n",
    "        neg_pred = model(user.reshape(-1, 1).expand(-1, args.test_n_neg), neg_items).view(-1, args.test_n_neg)\n",
    "        concat = torch.cat([test_pred, neg_pred], axis=1)\n",
    "        \n",
    "        _, indices = torch.topk(concat, 10)  # 10\n",
    "        indices = indices.numpy()\n",
    "        hit += (indices.size - np.count_nonzero(indices))\n",
    "        zero_idx = np.where(indices.reshape(-1) == 0)[0] % 10\n",
    "        ndcg += np.sum(np.reciprocal(np.log2(zero_idx + 2)))\n",
    "\n",
    "    hit_ratio = hit / len(info.test_dataset)\n",
    "    ndcg = ndcg / len(info.test_dataset)\n",
    "\n",
    "    print('[Evluating Epoch {}] total_loss = {:.4f}, HR = {:.4f}, NDCG = {:.4f} time = {:.4f}sec'.format(epoch_id, total_loss, hit_ratio, ndcg, timer()-start_epoch))\n",
    "    torch.save(model.state_dict(), \"checkpoints/GMF_Epoch{}_HR{:.4f}_NDCG{:.4f}.model\".format(epoch_id, hit_ratio, ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(args)\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Evluating Epoch 1] total_loss = 1637.5050, HR = 0.1399, NDCG = 0.1206 time = 150.2823sec\n",
      "[Evluating Epoch 2] total_loss = 42.8607, HR = 0.1359, NDCG = 0.1263 time = 151.2220sec\n",
      "[Evluating Epoch 3] total_loss = 22.5133, HR = 0.1568, NDCG = 0.1490 time = 222.1022sec\n",
      "[Evluating Epoch 4] total_loss = 18.3688, HR = 0.1571, NDCG = 0.1514 time = 135.6831sec\n",
      "[Evluating Epoch 5] total_loss = 9.6168, HR = 0.1618, NDCG = 0.1576 time = 148.7477sec\n",
      "[Evluating Epoch 6] total_loss = 17.6119, HR = 0.1678, NDCG = 0.1636 time = 163.9576sec\n",
      "[Evluating Epoch 7] total_loss = 13.9895, HR = 0.1716, NDCG = 0.1688 time = 158.4741sec\n",
      "[Evluating Epoch 8] total_loss = 5.6223, HR = 0.1736, NDCG = 0.1711 time = 167.8705sec\n",
      "[Evluating Epoch 9] total_loss = 5.4288, HR = 0.1772, NDCG = 0.1748 time = 170.5959sec\n",
      "[Evluating Epoch 10] total_loss = 5.9292, HR = 0.1758, NDCG = 0.1736 time = 176.3812sec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# epoch\n",
    "for epoch_id in range(1, args.epoch + 1):\n",
    "    train_loader = info.train_dataloader\n",
    "    start_epoch = timer()\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        user, item, rating = batch[0], batch[1], batch[2]\n",
    "        # mini-batch update\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(user, item)\n",
    "        loss = loss_function(prediction.view(-1), rating)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    hit = 0\n",
    "    ndcg = 0\n",
    "    test_loader = info.test_dataloader\n",
    "    for batch_idx, batch in enumerate(test_loader):\n",
    "        user, item, neg_items = batch[0], batch[1], batch[2]\n",
    "        # mini-batch update\n",
    "        test_pred = model(user, item)\n",
    "        neg_pred = model(user.reshape(-1, 1).expand(-1, args.test_n_neg), neg_items).view(-1, args.test_n_neg)\n",
    "        concat = torch.cat([test_pred, neg_pred], axis=1)\n",
    "        \n",
    "        _, indices = torch.topk(concat, 10)  # 10\n",
    "        indices = indices.numpy()\n",
    "        hit += (indices.size - np.count_nonzero(indices))\n",
    "        zero_idx = np.where(indices.reshape(-1) == 0)[0] % 10\n",
    "        ndcg += np.sum(np.reciprocal(np.log2(zero_idx + 2)))\n",
    "\n",
    "    hit_ratio = hit / len(info.test_dataset)\n",
    "    ndcg = ndcg / len(info.test_dataset)\n",
    "\n",
    "    print('[Evluating Epoch {}] total_loss = {:.4f}, HR = {:.4f}, NDCG = {:.4f} time = {:.4f}sec'.format(epoch_id, total_loss, hit_ratio, ndcg, timer()-start_epoch))\n",
    "    torch.save(model.state_dict(), \"checkpoints/MLP_Epoch{}_HR{:.4f}_NDCG{:.4f}.model\".format(epoch_id, hit_ratio, ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuMF(args)\n",
    "model.load_pretrain_weights()\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Evluating Epoch 1] total_loss = 7186.6720, HR = 0.2203, NDCG = 0.2036 time = 162.5721sec\n",
      "[Evluating Epoch 2] total_loss = 2912.6853, HR = 0.2107, NDCG = 0.1975 time = 286.6672sec\n",
      "[Evluating Epoch 3] total_loss = 2274.2859, HR = 0.2041, NDCG = 0.1924 time = 291.1469sec\n",
      "[Evluating Epoch 4] total_loss = 2159.6998, HR = 0.2014, NDCG = 0.1900 time = 283.0974sec\n",
      "[Evluating Epoch 5] total_loss = 2115.6284, HR = 0.2024, NDCG = 0.1923 time = 277.3113sec\n",
      "[Evluating Epoch 6] total_loss = 1845.9927, HR = 0.2012, NDCG = 0.1912 time = 279.4174sec\n",
      "[Evluating Epoch 7] total_loss = 1584.5817, HR = 0.2022, NDCG = 0.1922 time = 317.0147sec\n",
      "[Evluating Epoch 8] total_loss = 1569.8509, HR = 0.2011, NDCG = 0.1912 time = 276.6856sec\n",
      "[Evluating Epoch 9] total_loss = 1562.9941, HR = 0.2011, NDCG = 0.1914 time = 278.0450sec\n",
      "[Evluating Epoch 10] total_loss = 1554.9438, HR = 0.2001, NDCG = 0.1902 time = 278.6895sec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# epoch\n",
    "for epoch_id in range(1, args.epoch + 1):\n",
    "    train_loader = info.train_dataloader\n",
    "    start_epoch = timer()\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        user, item, rating = batch[0], batch[1], batch[2]\n",
    "        # mini-batch update\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(user, item)\n",
    "        loss = loss_function(prediction.view(-1), rating)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    hit = 0\n",
    "    ndcg = 0\n",
    "    test_loader = info.test_dataloader\n",
    "    for batch_idx, batch in enumerate(test_loader):\n",
    "        user, item, neg_items = batch[0], batch[1], batch[2]\n",
    "        # mini-batch update\n",
    "        test_pred = model(user, item)\n",
    "        neg_pred = model(user.reshape(-1, 1).expand(-1, args.test_n_neg), neg_items).view(-1, args.test_n_neg)\n",
    "        concat = torch.cat([test_pred, neg_pred], axis=1)\n",
    "        \n",
    "        _, indices = torch.topk(concat, 10)  # 10\n",
    "        indices = indices.numpy()\n",
    "        hit += (indices.size - np.count_nonzero(indices))\n",
    "        zero_idx = np.where(indices.reshape(-1) == 0)[0] % 10\n",
    "        ndcg += np.sum(np.reciprocal(np.log2(zero_idx + 2)))\n",
    "\n",
    "    hit_ratio = hit / len(info.test_dataset)\n",
    "    ndcg = ndcg / len(info.test_dataset)\n",
    "\n",
    "    print('[Evluating Epoch {}] total_loss = {:.4f}, HR = {:.4f}, NDCG = {:.4f} time = {:.4f}sec'.format(epoch_id, total_loss, hit_ratio, ndcg, timer()-start_epoch))\n",
    "    torch.save(model.state_dict(), \"checkpoints/NeuMF_Epoch{}_HR{:.4f}_NDCG{:.4f}.model\".format(epoch_id, hit_ratio, ndcg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a90aeebcf29d64a654773811cc170cb25061cb2498f10ac689db374c7bf325de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
